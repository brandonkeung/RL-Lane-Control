{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: highway-env in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages (1.10.1)\n",
      "Requirement already satisfied: gymnasium>=1.0.0a2 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages (from highway-env) (1.0.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages (from highway-env) (0.0.4)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages (from highway-env) (2.2.4)\n",
      "Requirement already satisfied: pygame>=2.0.2 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages (from highway-env) (2.6.1)\n",
      "Requirement already satisfied: matplotlib in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages (from highway-env) (3.10.0)\n",
      "Requirement already satisfied: pandas in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages (from highway-env) (2.2.3)\n",
      "Requirement already satisfied: scipy in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages (from highway-env) (1.15.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages (from gymnasium>=1.0.0a2->highway-env) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages (from gymnasium>=1.0.0a2->highway-env) (4.12.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages (from matplotlib->highway-env) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages (from matplotlib->highway-env) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages (from matplotlib->highway-env) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages (from matplotlib->highway-env) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages (from matplotlib->highway-env) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages (from matplotlib->highway-env) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages (from matplotlib->highway-env) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages (from matplotlib->highway-env) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages (from pandas->highway-env) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages (from pandas->highway-env) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->highway-env) (1.17.0)\n",
      "Collecting stable-baselines3\n",
      "  Downloading stable_baselines3-2.6.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: gymnasium<1.2.0,>=0.29.1 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages (from stable-baselines3) (1.0.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.20 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages (from stable-baselines3) (2.2.4)\n",
      "Requirement already satisfied: torch<3.0,>=2.3 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages (from stable-baselines3) (2.6.0)\n",
      "Requirement already satisfied: cloudpickle in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages (from stable-baselines3) (3.1.1)\n",
      "Requirement already satisfied: pandas in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages (from stable-baselines3) (2.2.3)\n",
      "Requirement already satisfied: matplotlib in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages (from stable-baselines3) (3.10.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages (from gymnasium<1.2.0,>=0.29.1->stable-baselines3) (4.12.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages (from gymnasium<1.2.0,>=0.29.1->stable-baselines3) (0.0.4)\n",
      "Requirement already satisfied: filelock in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable-baselines3) (3.18.0)\n",
      "Requirement already satisfied: networkx in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable-baselines3) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable-baselines3) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable-baselines3) (2025.3.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable-baselines3) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages (from matplotlib->stable-baselines3) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages (from matplotlib->stable-baselines3) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages (from matplotlib->stable-baselines3) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages (from matplotlib->stable-baselines3) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages (from matplotlib->stable-baselines3) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages (from matplotlib->stable-baselines3) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages (from matplotlib->stable-baselines3) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages (from matplotlib->stable-baselines3) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages (from pandas->stable-baselines3) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages (from pandas->stable-baselines3) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages (from jinja2->torch<3.0,>=2.3->stable-baselines3) (3.0.2)\n",
      "Downloading stable_baselines3-2.6.0-py3-none-any.whl (184 kB)\n",
      "Installing collected packages: stable-baselines3\n",
      "Successfully installed stable-baselines3-2.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install highway-env\n",
    "!pip install stable-baselines3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import highway_env\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('highway-v0', render_mode='rgb_array')\n",
    "\n",
    "env.unwrapped.config[\"observation\"][\"type\"] = \"Kinematics\"\n",
    "env.unwrapped.config[\"vehicles_count\"] = 10\n",
    "env.unwrapped.config[\"duration\"] = 40\n",
    "env.reset()\n",
    "\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.n\n",
    "print(state_dim, action_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super(DQN, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(state_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, action_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity=100_000):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "\n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        batch = random.sample(self.buffer, batch_size)\n",
    "        states, actions, rewards, next_states, dones = zip(*batch)\n",
    "        return (\n",
    "            torch.tensor(np.array(states), dtype=torch.float32),\n",
    "            torch.tensor(actions, dtype=torch.long),\n",
    "            torch.tensor(rewards, dtype=torch.float32),\n",
    "            torch.tensor(np.array(next_states), dtype=torch.float32),\n",
    "            torch.tensor(dones, dtype=torch.float32)\n",
    "        )\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0, Total Reward: 4.78, Epsilon: 0.99\n",
      "Episode 1, Total Reward: 9.84, Epsilon: 0.99\n",
      "Episode 2, Total Reward: 10.64, Epsilon: 0.99\n",
      "Episode 3, Total Reward: 1.96, Epsilon: 0.98\n",
      "Episode 4, Total Reward: 3.84, Epsilon: 0.98\n",
      "Episode 5, Total Reward: 5.11, Epsilon: 0.97\n",
      "Episode 6, Total Reward: 8.41, Epsilon: 0.97\n",
      "Episode 7, Total Reward: 2.46, Epsilon: 0.96\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Index tensor must have the same number of dimensions as input tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 50\u001b[0m\n\u001b[1;32m     47\u001b[0m dones \u001b[38;5;241m=\u001b[39m dones\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Q(s, a)\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m q_values \u001b[38;5;241m=\u001b[39m \u001b[43mq_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstates\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# max_a' Q_target(s', a')\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Index tensor must have the same number of dimensions as input tensor"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "q_net = DQN(state_dim, action_dim).to(device)\n",
    "target_q_net = DQN(state_dim, action_dim).to(device)\n",
    "target_q_net.load_state_dict(q_net.state_dict())\n",
    "\n",
    "optimizer = optim.Adam(q_net.parameters(), lr=1e-4)\n",
    "buffer = ReplayBuffer()\n",
    "batch_size = 64\n",
    "gamma = 0.99\n",
    "epsilon = 1.0\n",
    "epsilon_min = 0.05\n",
    "epsilon_decay = 0.995\n",
    "target_update_freq = 10\n",
    "num_episodes = 500\n",
    "\n",
    "rewards_history = []\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    obs, _ = env.reset()\n",
    "    total_reward = 0\n",
    "\n",
    "    for t in range(200):\n",
    "        # Epsilon-greedy action selection\n",
    "        if random.random() < epsilon:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                state_tensor = torch.tensor(obs, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "                q_values = q_net(state_tensor)\n",
    "                action = q_values.argmax().item()\n",
    "\n",
    "        next_obs, reward, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        buffer.push(obs, action, reward, next_obs, done)\n",
    "\n",
    "        obs = next_obs\n",
    "        total_reward += reward\n",
    "\n",
    "        # Training\n",
    "        if len(buffer) > batch_size:\n",
    "            states, actions, rewards, next_states, dones = buffer.sample(batch_size)\n",
    "\n",
    "            states = states.to(device)\n",
    "            actions = actions.to(device)\n",
    "            rewards = rewards.to(device)\n",
    "            next_states = next_states.to(device)\n",
    "            dones = dones.to(device)\n",
    "\n",
    "            # Q(s, a)\n",
    "            q_values = q_net(states).gather(1, actions.unsqueeze(1)).squeeze()\n",
    "\n",
    "            # max_a' Q_target(s', a')\n",
    "            with torch.no_grad():\n",
    "                max_next_q_values = target_q_net(next_states).max(1)[0]\n",
    "                target = rewards + gamma * max_next_q_values * (1 - dones)\n",
    "\n",
    "            loss = nn.MSELoss()(q_values, target)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    # Update target network\n",
    "    if episode % target_update_freq == 0:\n",
    "        target_q_net.load_state_dict(q_net.state_dict())\n",
    "\n",
    "    # Decay epsilon\n",
    "    epsilon = max(epsilon_min, epsilon * epsilon_decay)\n",
    "    rewards_history.append(total_reward)\n",
    "    print(f\"Episode {episode}, Total Reward: {total_reward:.2f}, Epsilon: {epsilon:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rewards_history)\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Total Reward\")\n",
    "plt.title(\"DQN Learning Progress\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m env \u001b[38;5;241m=\u001b[39m make_vec_env(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhighway-v0\u001b[39m\u001b[38;5;124m\"\u001b[39m, n_envs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m PPO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMlpPolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m, env, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# total_timesteps=100_000\u001b[39;00m\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mppo_lane_keeping\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages/stable_baselines3/ppo/ppo.py:311\u001b[0m, in \u001b[0;36mPPO.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[1;32m    304\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    309\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    310\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[0;32m--> 311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages/stable_baselines3/common/on_policy_algorithm.py:324\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[0;32m--> 324\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m continue_training:\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages/stable_baselines3/common/on_policy_algorithm.py:218\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;66;03m# Otherwise, clip the actions to avoid out of bound error\u001b[39;00m\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;66;03m# as we are sampling from an unbounded Gaussian distribution\u001b[39;00m\n\u001b[1;32m    216\u001b[0m         clipped_actions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(actions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mlow, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mhigh)\n\u001b[0;32m--> 218\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclipped_actions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mnum_envs\n\u001b[1;32m    222\u001b[0m \u001b[38;5;66;03m# Give access to local variables\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:222\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \n\u001b[1;32m    218\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[0;32m--> 222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:59\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;66;03m# Avoid circular imports\u001b[39;00m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs):\n\u001b[0;32m---> 59\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews[env_idx], terminated, truncated, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[assignment]\u001b[39;49;00m\n\u001b[1;32m     60\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;66;03m# convert to SB3 VecEnv api\u001b[39;00m\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx] \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages/stable_baselines3/common/monitor.py:94\u001b[0m, in \u001b[0;36mMonitor.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneeds_reset:\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTried to step environment that needs reset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 94\u001b[0m observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrewards\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m(reward))\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages/gymnasium/wrappers/common.py:393\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages/gymnasium/core.py:322\u001b[0m, in \u001b[0;36mWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28mself\u001b[39m, action: WrapperActType\n\u001b[1;32m    320\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m    321\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Uses the :meth:`step` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages/gymnasium/wrappers/common.py:285\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages/highway_env/envs/common/abstract.py:240\u001b[0m, in \u001b[0;36mAbstractEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    236\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe road and vehicle must be initialized in the environment implementation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    237\u001b[0m     )\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpolicy_frequency\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 240\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_simulate\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_type\u001b[38;5;241m.\u001b[39mobserve()\n\u001b[1;32m    243\u001b[0m reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reward(action)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages/highway_env/envs/common/abstract.py:271\u001b[0m, in \u001b[0;36mAbstractEnv._simulate\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    260\u001b[0m     action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmanual_control\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    268\u001b[0m ):\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_type\u001b[38;5;241m.\u001b[39mact(action)\n\u001b[0;32m--> 271\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroad\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimulation_frequency\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages/highway_env/road/road.py:464\u001b[0m, in \u001b[0;36mRoad.act\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Decide the actions of each entity on the road.\"\"\"\u001b[39;00m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m vehicle \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvehicles:\n\u001b[0;32m--> 464\u001b[0m     \u001b[43mvehicle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages/highway_env/vehicle/behavior.py:115\u001b[0m, in \u001b[0;36mIDMVehicle.act\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    110\u001b[0m action[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msteering\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(\n\u001b[1;32m    111\u001b[0m     action[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msteering\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mMAX_STEERING_ANGLE, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mMAX_STEERING_ANGLE\n\u001b[1;32m    112\u001b[0m )\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# Longitudinal: IDM\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m front_vehicle, rear_vehicle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mneighbour_vehicles\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlane_index\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m action[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macceleration\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macceleration(\n\u001b[1;32m    119\u001b[0m     ego_vehicle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, front_vehicle\u001b[38;5;241m=\u001b[39mfront_vehicle, rear_vehicle\u001b[38;5;241m=\u001b[39mrear_vehicle\n\u001b[1;32m    120\u001b[0m )\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# When changing lane, check both current and target lanes\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/envs/RL311/lib/python3.11/site-packages/highway_env/road/road.py:506\u001b[0m, in \u001b[0;36mRoad.neighbour_vehicles\u001b[0;34m(self, vehicle, lane_index)\u001b[0m\n\u001b[1;32m    504\u001b[0m s_v, lat_v \u001b[38;5;241m=\u001b[39m lane\u001b[38;5;241m.\u001b[39mlocal_coordinates(v\u001b[38;5;241m.\u001b[39mposition)\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lane\u001b[38;5;241m.\u001b[39mon_lane(v\u001b[38;5;241m.\u001b[39mposition, s_v, lat_v, margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 506\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m s \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m s_v \u001b[38;5;129;01mand\u001b[39;00m (s_front \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m s_v \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m s_front):\n\u001b[1;32m    508\u001b[0m     s_front \u001b[38;5;241m=\u001b[39m s_v\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env = make_vec_env(\"highway-v0\", n_envs=4)\n",
    "\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=10) # total_timesteps=100_000\n",
    "model.save(\"ppo_lane_keeping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
